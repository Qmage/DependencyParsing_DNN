{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Dependency Parser with deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating Vocabulary from the training data\n",
    "First we should read from data file. The data looks like the following\n",
    "```txt\n",
    "Two     NUM\n",
    "of      ADP\n",
    "them    PRON\n",
    "were    AUX\n",
    "being   AUX\n",
    "run     VERB\n",
    "by      ADP\n",
    "2       NUM\n",
    "officials       NOUN\n",
    "of      ADP\n",
    "the     DET\n",
    "Ministry        PROPN\n",
    "of      ADP\n",
    "the     DET\n",
    "Interior        PROPN\n",
    "!       PUNCT\n",
    "\n",
    "The     DET\n",
    "MoI     PROPN\n",
    "in      ADP\n",
    "Iraq    PROPN\n",
    "is      AUX\n",
    "equivalent      ADJ\n",
    "to      ADP\n",
    "the     DET\n",
    "US      PROPN\n",
    "FBI     PROPN\n",
    ",       PUNCT\n",
    "so      ADV\n",
    "this    PRON\n",
    "would   AUX\n",
    "be      VERB\n",
    "like    SCONJ\n",
    "having  VERB\n",
    "J.      PROPN\n",
    "Edgar   PROPN\n",
    "Hoover  PROPN\n",
    "unwittingly     ADV\n",
    "employ  VERB\n",
    "at      ADP\n",
    "a       DET\n",
    "high    ADJ\n",
    "level   NOUN\n",
    "members NOUN\n",
    "of      ADP\n",
    "the     DET\n",
    "Weathermen      PROPN\n",
    "bombers NOUN\n",
    "back    ADV\n",
    "in      ADP\n",
    "the     DET\n",
    "1960s   NOUN\n",
    ".       PUNCT\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabs_word_path = \"data/vocabs.word\"\n",
    "vocabs_pos_path = \"data/vocabs.pos\"\n",
    "vocabs_label_path = \"data/vocabs.labels\"\n",
    "vocabs_action_path = \"data/vocabs.actions\"\n",
    "\n",
    "#create string to integer mapping (because neural network libraries work with integers)\n",
    "word_dict = {l.split(\" \")[0]:int(l.split(\" \")[1]) for l in open(vocabs_word_path, 'r').read().strip().split('\\n')}\n",
    "pos_dict = {l.split(\" \")[0]:int(l.split(\" \")[1]) for l in open(vocabs_pos_path, 'r').read().strip().split('\\n')}\n",
    "label_dict = {l.split(\" \")[0]:int(l.split(\" \")[1]) for l in open(vocabs_label_path, 'r').read().strip().split('\\n')}\n",
    "action_dict = {l.split(\" \")[0]:int(l.split(\" \")[1]) for l in open(vocabs_action_path, 'r').read().strip().split('\\n')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We define some auxiliary functions to access the words, tag feature and tag output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def actionid2action_str(id):\n",
    "    return actions[id]\n",
    "\n",
    "def action2id(action):\n",
    "    return action_dict[action]\n",
    "\n",
    "def label2id(label):\n",
    "    return label_dict[label]\n",
    "\n",
    "def pos2id(pos):\n",
    "    return pos_dict[pos] if pos in pos_dict else 999\n",
    "\n",
    "def word2id(word):\n",
    "    return word_dict[word] if word in word_dict else word_dict['<unk>']\n",
    "\n",
    "def num_words():\n",
    "    return len(word_dict)\n",
    "\n",
    "def num_pos():\n",
    "    return len(pos_dict)\n",
    "\n",
    "def num_labels():\n",
    "    return len(label_dict)\n",
    "\n",
    "def num_actions():\n",
    "    return len(action_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "%matplotlib inline\n",
    "import dynet\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Steps in deep network design\n",
    "1. Define the model (parameter container)\n",
    "2. Define updater (e.g. SGD or ADAM) and bound it to the model\n",
    "3. Define parameters (embeddings and other parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set values for the various parameters\n",
    "trainer = 'amsgrad' # {amsgrad, adam, rmsprop, adadelta, adagrad, momentumsgd}\n",
    "epochs = 10\n",
    "activation = 'rectify' # {rectify, tanh, logistic}\n",
    "word_embed_dim, pos_embed_dim, label_embed_dim = 96, 64, 64\n",
    "minibatch_size = 1000\n",
    "hidden1_dim, hidden2_dim = 500, 500\n",
    "dropout = 0.3\n",
    "model_path = \"trained_part7.model\"\n",
    "model_param = {\"trainer\":trainer,\n",
    "               \"epochs\":epochs,\n",
    "               \"activation\":activation,\n",
    "               \"word_embed_dim\":word_embed_dim,\n",
    "               \"pos_embed_dim\":pos_embed_dim,\n",
    "               \"label_embed_dim\":label_embed_dim,\n",
    "               \"minibatch_size\":minibatch_size,\n",
    "               \"hidden1_dim\":hidden1_dim,\n",
    "               \"hidden2_dim\":hidden2_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# first initialize a computation graph container (or model).\n",
    "model = dynet.Model()\n",
    "\n",
    "#functions to save and load the network\n",
    "def load(filename):\n",
    "    model.populate(filename)\n",
    "\n",
    "def save(filename):\n",
    "    model.save(filename)\n",
    "\n",
    "# assign the algorithm for backpropagation updates.\n",
    "updater = {\"amsgrad\":dynet.AmsgradTrainer,\n",
    "           \"adam\":dynet.AdamTrainer,\n",
    "           \"rmsprop\":dynet.RMSPropTrainer,\n",
    "           \"adadelta\":dynet.AdadeltaTrainer,\n",
    "           \"adagrad\":dynet.AdagradTrainer, \n",
    "           \"momentumsgd\":dynet.MomentumSGDTrainer}[trainer](model)\n",
    "\n",
    "# assign transfer function\n",
    "transfer = {\"rectify\":dynet.rectify, \n",
    "            \"tanh\":dynet.tanh,\n",
    "            \"logistic\":dynet.logistic}[activation] \n",
    "\n",
    "# create embeddings for words, pos and label features.\n",
    "word_embedding = model.add_lookup_parameters((num_words(), word_embed_dim))\n",
    "pos_embedding = model.add_lookup_parameters((num_pos(), pos_embed_dim))\n",
    "label_embedding = model.add_lookup_parameters((num_labels(), label_embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# define the input dimension for the embedding layer.\n",
    "# here we assume to see two words after and before and current word (meaning 5 word embeddings)\n",
    "# and to see the last two predicted tags (meaning two tag embeddings)\n",
    "input_dim = 20 * word_embed_dim + 20 * pos_embed_dim + 12 * label_embed_dim\n",
    "\n",
    "# define the hidden layer 1.\n",
    "hidden1_layer = model.add_parameters((hidden1_dim, input_dim))\n",
    "\n",
    "# define the hidden layer 1 bias term and initialize it as constant 0.01.\n",
    "hidden1_layer_bias = model.add_parameters(hidden1_dim, init=dynet.ConstInitializer(0.01))\n",
    "\n",
    "# define the hidden layer 2.\n",
    "hidden2_layer = model.add_parameters((hidden2_dim, hidden1_dim))\n",
    "\n",
    "# define the hidden layer 2 bias term and initialize it as constant 0.01.\n",
    "hidden2_layer_bias = model.add_parameters(hidden2_dim, init=dynet.ConstInitializer(0.01))\n",
    "\n",
    "# define the output weight.\n",
    "output_layer = model.add_parameters((num_actions(), hidden2_dim))\n",
    "\n",
    "# define the bias vector and initialize it as constant 0.01.\n",
    "output_bias = model.add_parameters(num_actions(), init=dynet.ConstInitializer(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementing the Forward function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def forward(features):\n",
    "    # extract word, pos and label ids\n",
    "    word_ids = [word2id(word) for word in features[0:20]]\n",
    "    pos_ids = [pos2id(pos) for pos in features[20:40]]\n",
    "    label_ids = [label2id(label) for label in features[40:52]]\n",
    "\n",
    "    # extract word embeddings and tag embeddings from features\n",
    "    word_embeds = [word_embedding[wid] for wid in word_ids]\n",
    "    pos_embeds = [pos_embedding[pid] if pid!=999 else dynet.zeros(pos_embed_dim) for pid in pos_ids]\n",
    "    label_embeds = [label_embedding[lid] for lid in label_ids]\n",
    "\n",
    "    # concatenating all features\n",
    "    embedding_layer = dynet.concatenate(word_embeds + pos_embeds + label_embeds)\n",
    "    if dropout != 0.0:\n",
    "        embedding_layer = dynet.dropout(embedding_layer, dropout)\n",
    "\n",
    "    # calculating the hidden layer 1\n",
    "    # .expr() converts a parameter to a matrix expression in dynetnet (its a dynetnet-specific syntax).\n",
    "    hidden1 = transfer(hidden1_layer.expr() * embedding_layer + hidden1_layer_bias.expr())\n",
    "    if dropout != 0.0:\n",
    "        hidden1 = dynet.dropout(hidden1, dropout)\n",
    "     # calculating the hidden layer 2\n",
    "    hidden2 = transfer(hidden2_layer.expr() * hidden1 + hidden1_layer_bias.expr())\n",
    "    if dropout != 0.0:\n",
    "        hidden2 = dynet.dropout(hidden2, dropout)\n",
    "\n",
    "    # calculating the output layer\n",
    "    output = output_layer.expr() * hidden2 + output_bias.expr()\n",
    "\n",
    "    # return a list of outputs\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training with backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading the training data into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = 'data/train.data'\n",
    "train_data = open(train_data_path, 'r').read().strip().split('\\n')\n",
    "loss_values = []\n",
    "\n",
    "def train_iter(train_data):\n",
    "    losses = [] # minibatch loss vector\n",
    "    random.shuffle(train_data) # shuffle the training data.\n",
    "\n",
    "    for line in train_data:\n",
    "        fields = line.strip().split(' ')\n",
    "        features, label, gold_label = fields[:-1], fields[-1], action2id(fields[-1])\n",
    "        result = forward(features)\n",
    "\n",
    "        # getting loss with respect to negative log softmax function and the gold label; and appending to the minibatch losses.\n",
    "        loss = dynet.pickneglogsoftmax(result, gold_label)\n",
    "        losses.append(loss)\n",
    "\n",
    "        if len(losses) >= minibatch_size:\n",
    "            minibatch_loss = dynet.esum(losses) / len(losses) # now we have enough loss values to get loss for minibatch\n",
    "            minibatch_loss.forward() # calling dynetnet to run forward computation for all minibatch items\n",
    "            minibatch_loss_value = minibatch_loss.value() # getting float value of the loss for current minibatch\n",
    "\n",
    "            # printing info and plotting\n",
    "            loss_values.append(minibatch_loss_value)\n",
    "\n",
    "            #if len(loss_values)%10==0: plot(loss_values)\n",
    "\n",
    "            minibatch_loss.backward() # calling dynetnet to run backpropagation\n",
    "            updater.update() # calling dynet to change parameter values with respect to current backpropagation\n",
    "\n",
    "            # empty the loss vector and refresh the memory of dynetnet\n",
    "            losses = []\n",
    "            dynet.renew_cg()\n",
    "\n",
    "    dynet.renew_cg() # there are still some minibatch items in the memory but they are smaller than the minibatch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    for i in range(epochs):\n",
    "        print 'epoch', (i+1)\n",
    "        train_iter(train_data)\n",
    "        dynet.renew_cg()\n",
    "    print 'finished training!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "epoch 2\n",
      "epoch 3\n",
      "epoch 4\n",
      "epoch 5\n",
      "epoch 6\n",
      "epoch 7\n",
      "epoch 8\n",
      "epoch 9\n",
      "epoch 10\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113ba6d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "plt.title(\"Loss over time\")\n",
    "plt.xlabel(\"Minibatch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "ax.set_xlim([0, len(loss_values)+10])\n",
    "ax.plot(loss_values)\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(model_path)\n",
    "with open(model_path+\".json\", 'w') as fp:\n",
    "    json.dump(model_param, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parsing a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#implementing decoder\n",
    "def predict(features):\n",
    "    # running forward\n",
    "    output = forward(features)\n",
    "\n",
    "    # getting list value of the output\n",
    "    scores = output.npvalue()\n",
    "\n",
    "    # refresh dynet memory (computation graph)\n",
    "    dynet.renew_cg()\n",
    "    \n",
    "    # if returning best action, get best tag id, then get the string\n",
    "    best_action_id = np.argmax(scores)\n",
    "    return actionid2action_str(best_action_id)\n",
    "    \n",
    "    \"\"\"\n",
    "    # if returning the score only\n",
    "    return scores\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file = 'data/en.pos.dev'\n",
    "writer = open(test_file+'.output', 'w')\n",
    "for sentence in open(test_file, 'r'):\n",
    "    # get the features in a list by splitting the input by space/tab, excluding the last one\n",
    "    features = sentence.strip().split()[:-1]\n",
    "    action = predict(features)\n",
    "    output = \"\\t\".join(features+action)\n",
    "    writer.write('\\n'.join(output) + '\\n\\n')\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
